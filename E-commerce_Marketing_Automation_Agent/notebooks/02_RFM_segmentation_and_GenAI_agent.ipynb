{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c91eaf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from huggingface_hub import InferenceClient\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types, text, Engine\n",
    "import time\n",
    "\n",
    "from src import database_methods as dbm\n",
    "from src import ai_agent_methods as aiam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8af7e3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model answer (What is the capital of France?):\n",
      "The capital of France is **Paris**.\n"
     ]
    }
   ],
   "source": [
    "client: InferenceClient = InferenceClient(\n",
    "    api_key=os.environ[\"HF_TOKEN\"],\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"openai/gpt-oss-120b:groq\", \n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the capital of France?\"\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    print(f\"Model answer (What is the capital of France?):\\n{completion.choices[0].message.content}\")\n",
    "except Exception as e:\n",
    "    print(\"Model unsuccessfully loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f652e6",
   "metadata": {},
   "source": [
    "## Due to the fact that the data did not contain customer e-mail data, e-mail addresses will be generated, especially for the project, from the prefix \"client_\", customer_id, and the suffix \"@mail.com\".\n",
    "\n",
    "## This data will be generated in an SQL query along with other parameters that will be useful for the AI ​​Agent to send emails to customers who have been inactive for some time to active customers for whom a discount in the store will be provided, encouraging them to make further purchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c7b8ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB Engine successfuly created\n",
      "     customer_id  monetary  frequency  recency  average_order_value  churn  \\\n",
      "1114       13658  10373.48          5        9              2074.70      0   \n",
      "2462       15382  40748.55          6       14              6791.43      0   \n",
      "4484       17965  18415.04         14       37              1315.36      0   \n",
      "1208       13775     11.53          1      142                11.53      1   \n",
      "1975       14764   2232.72          1       46              2232.72      0   \n",
      "\n",
      "                        email  \n",
      "1114  customer_13658@mail.com  \n",
      "2462  customer_15382@mail.com  \n",
      "4484  customer_17965@mail.com  \n",
      "1208  customer_13775@mail.com  \n",
      "1975  customer_14764@mail.com  \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    engine: Engine = dbm.get_db_engine()\n",
    "    print(\"DB Engine successfuly created\")\n",
    "except Exception as e:\n",
    "    print(f\"DB Engine creation error: {e}\")\n",
    "\n",
    "query: str = \"\"\"\n",
    "SELECT \n",
    "    customer_id, \n",
    "    SUM(quantity * price) AS monetary, \n",
    "    COUNT (DISTINCT order_id) AS frequency,\n",
    "    ((SELECT MAX(date) FROM e_commerce_order_details) - MAX(date)) AS recency, \n",
    "    ROUND((SUM(quantity * price) / (COUNT (DISTINCT order_id))), 2) AS average_order_value, \n",
    "\tCASE\n",
    "\t\tWHEN \n",
    "\t\t\t((SELECT MAX(date) FROM e_commerce_order_details) - MAX(date)) >= 90\n",
    "\t\tTHEN\n",
    "\t\t\t1\n",
    "\t\tELSE\n",
    "\t\t\t0\n",
    "\tEND AS churn, \n",
    "\tCONCAT('customer_', customer_id,'@mail.com') AS email\n",
    "FROM \n",
    "\te_commerce_order_details\n",
    "GROUP BY \n",
    "    customer_id;\n",
    "\"\"\"\n",
    "df_rfm: pd.DataFrame = pd.read_sql(\n",
    "    query, \n",
    "    engine\n",
    ")\n",
    "\n",
    "print(df_rfm.sample(5))\n",
    "del query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c354297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monetary threshold:\n",
      "14660.86 \n",
      "\n",
      "Frequency threshold:\n",
      "5.0 \n",
      "\n",
      "Average order value threshold:\n",
      "3616.08 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold_monetary: np.float64 = np.round(df_rfm[\"monetary\"].quantile(0.80), 2)\n",
    "print(f\"Monetary threshold:\\n{threshold_monetary}\", \"\\n\")\n",
    "threshold_frequency: np.float64 = np.round(df_rfm[\"frequency\"].quantile(0.80), 2)\n",
    "print(f\"Frequency threshold:\\n{threshold_frequency}\", \"\\n\")\n",
    "threshold_aov: np.float64 = np.round(df_rfm[\"average_order_value\"].quantile(0.80), 2)\n",
    "print(f\"Average order value threshold:\\n{threshold_aov}\", \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e57d214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     customer_id  monetary  frequency  recency  average_order_value  churn  \\\n",
      "0          12004   1509.60          1      227              1509.60      1   \n",
      "1          12006     24.76          1      218                24.76      1   \n",
      "2          12008   5689.57          1      276              5689.57      1   \n",
      "3          12013     69.96          1      359                69.96      1   \n",
      "4          12024    149.52          1      176               149.52      1   \n",
      "...          ...       ...        ...      ...                  ...    ...   \n",
      "4713       18280    623.26          1      277               623.26      1   \n",
      "4714       18281    576.58          1      180               576.58      1   \n",
      "4715       18282   1044.86          2        7               522.43      0   \n",
      "4716       18283  12114.61         16        3               757.16      0   \n",
      "4717       18287  18139.56          3       42              6046.52      0   \n",
      "\n",
      "                        email    segmentation  \n",
      "0     customer_12004@mail.com  churn_recovery  \n",
      "1     customer_12006@mail.com  churn_recovery  \n",
      "2     customer_12008@mail.com  churn_recovery  \n",
      "3     customer_12013@mail.com  churn_recovery  \n",
      "4     customer_12024@mail.com  churn_recovery  \n",
      "...                       ...             ...  \n",
      "4713  customer_18280@mail.com  churn_recovery  \n",
      "4714  customer_18281@mail.com  churn_recovery  \n",
      "4715  customer_18282@mail.com  standard_promo  \n",
      "4716  customer_18283@mail.com     vip_loyalty  \n",
      "4717  customer_18287@mail.com     vip_loyalty  \n",
      "\n",
      "[4718 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "conditions: list[pd.Series]= [\n",
    "    (df_rfm[\"churn\"] == 1),\n",
    "    (\n",
    "        (df_rfm[\"churn\"] == 0) & (\n",
    "            (df_rfm[\"monetary\"] >= threshold_monetary)\n",
    "            | \n",
    "            (df_rfm[\"frequency\"] >= threshold_frequency)\n",
    "            | \n",
    "            (df_rfm[\"average_order_value\"] >= threshold_aov)\n",
    "            )\n",
    "    )\n",
    "]\n",
    "choice: list[str] = [\n",
    "    \"churn_recovery\", \n",
    "    \"vip_loyalty\"\n",
    "]\n",
    "\n",
    "df_rfm[\"segmentation\"] = np.select(conditions, choice, default=\"standard_promo\")\n",
    "print(df_rfm)\n",
    "del threshold_monetary, threshold_frequency, threshold_aov, choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00324350",
   "metadata": {},
   "outputs": [],
   "source": [
    "vip_loyalty_prompt: str = r\"\"\"\n",
    "    You are a Customer Success Manager for a premium brand. \n",
    "    Write a short, exclusive appreciation email to our VIP customer. \n",
    "    Thank them for their loyalty. \n",
    "    Offer a special 20% discount on their next purchase with code: VIP20. \n",
    "    Tone: Professional, grateful, and exclusive. \n",
    "    Keep it under 100 words. Do not use hashtags.\n",
    "\"\"\"\n",
    "churn_recovery_prompt: str = r\"\"\"\n",
    "    You are a warm and friendly Customer Support Specialist. \n",
    "    Write a 'We Miss You' email to a customer who hasn't purchased in a while. \n",
    "    Convince them to come back. \n",
    "    Offer a 15% welcome back discount with code: MISSYOU15. \n",
    "    Tone: Empathetic, warm, casual. \n",
    "    Keep it under 80 words.\"\n",
    "\"\"\"\n",
    "\n",
    "standard_promo_prompt: str = r\"\"\"\n",
    "    You are an energetic Marketing Copywriter. \n",
    "    Write a catchy promotional email to an active customer. \n",
    "    Encourage them to check out our new arrivals. \n",
    "    Offer a 10% discount on the next order with code: HELLO10. \n",
    "    Tone: Exciting, direct, sales-oriented. \n",
    "    Keep it under 80 words.\n",
    "\"\"\"\n",
    "\n",
    "prompt: dict[str,str] = {\n",
    "    \"vip_loyalty\": vip_loyalty_prompt, \n",
    "    \"churn_recovery\": churn_recovery_prompt, \n",
    "    \"standard_promo\": standard_promo_prompt\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f36a507",
   "metadata": {},
   "source": [
    "## Methodology: AI Content Generation & API Integration\n",
    "This module implements an LLM-based (Large Language Model) agent to automate personalized marketing communication. Below are the key technical decisions and the rationale behind the chosen data flow architecture.\n",
    "\n",
    "1. Simulation Mode (\"Dry Run\") & Data Safety\n",
    "For safety reasons and development purposes, no actual emails are transmitted to customer addresses.\n",
    "\n",
    "Process: Generated content is stored directly within the pandas.DataFrame as a new feature (email_draft).\n",
    "\n",
    "Persistence: Upon completion, the enriched dataset is exported to a .csv file. This allows for a Human-in-the-Loop (HITL) approach, where drafts undergo Quality Assurance (QA) before any potential production deployment.\n",
    "\n",
    "2. Sequential Execution Strategy (Single-Threaded)\n",
    "The system utilizes the pandas.apply() method for row-by-row processing. While vectorization is typically preferred in Data Science for performance, sequential processing is the optimal architectural choice in this specific context.\n",
    "\n",
    "I deliberately avoided Parallel Processing (e.g., joblib, multiprocessing) due to the constraints of the external API:\n",
    "\n",
    "Traffic Control: Using a sequential loop within .apply() allows for precise pacing via time.sleep(). This ensures the script respects the API's concurrency limits and maintains stability throughout the ETL process.\n",
    "\n",
    "I/O Bound Process: The bottleneck is not local CPU computation power, but Network Latency (waiting for the server to generate text).\n",
    "\n",
    "3. Operational Scope & Sampling Strategy\n",
    "To ensure high availability and model performance, the system utilizes the Groq AI inference provider (via Hugging Face integration).\n",
    "\n",
    "Due to the strict usage quotas and rate limits associated with the free tier of this provider, the generation process is strictly limited to a representative sample of the first 50 customers (df_rfm.head(50)).\n",
    "\n",
    "Rationale: This sample size is sufficient to validate the Proof of Concept (PoC) and demonstrate the efficacy of the personalization prompts without incurring overage costs or triggering API blocks.\n",
    "\n",
    "Scalability: The architecture is designed to scale to the full dataset (N=4000+) instantly upon upgrading to a paid enterprise plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da4a4df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email drafts successfully generated\n",
      "Dear Customer 16971,\n",
      "\n",
      "We’ve just stocked fresh arrivals you’ll love—stylish, unique pieces ready to revamp your wardrobe.\n",
      "\n",
      "Explore now and enjoy an exclusive 10% off your next order with code HELLO10. Hurry, the new collection won’t wait!\n",
      "\n",
      "Tap the link below and treat yourself today.\n",
      "\n",
      "Best regards,\n",
      "The Wojciech Kiełbowicz & Co Team\n",
      "--------------------------------------------------\n",
      "Dear Customer 14650,\n",
      "\n",
      "We’ve noticed it’s been a while since your last visit and we truly miss having you with us. Your satisfaction means a lot, and we’d love to welcome you back.\n",
      "\n",
      "Enjoy a 15% welcome‑back discount on your next order with code MISSYOU15. Hope to see you soon!\n",
      "\n",
      "Best regards,\n",
      "The Wojciech Kiełbowicz & Co Team\n",
      "--------------------------------------------------\n",
      "Dear Customer 17912,\n",
      "\n",
      "We’ve missed you at Wojciech Kiełbowicz & Co! It’s been a while since your last visit, and we hope everything’s been great for you.\n",
      "\n",
      "To show our appreciation, here’s a 15% welcome‑back discount—just use code MISSYOU15 at checkout. We’d love to see you explore our newest collections.\n",
      "\n",
      "Best regards,\n",
      "The Wojciech Kiełbowicz & Co Team\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df_test: pd.DataFrame = df_rfm.sample(3)\n",
    "try:\n",
    "    df_test[\"email_draft\"] = df_test.apply(aiam.generate_email, axis=1, args=(client, prompt))\n",
    "    print(\"Email drafts successfully generated\")\n",
    "except Exception as e:\n",
    "    print(f\"Email drafts unsuccessfully generated. Error: {e}\")\n",
    "\n",
    "for i in range(3):\n",
    "    print(df_test[\"email_draft\"].iloc[i])\n",
    "    print(50 * \"-\")\n",
    "del df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c05d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email drafts are being generated...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Email drafts are being generated...\")\n",
    "    df_rfm[\"email_draft\"] = df_rfm.head(50).apply(aiam.generate_email, axis=1, args=(client,prompt))\n",
    "    print(\"Email drafts successfully generated\")\n",
    "except Exception as e:\n",
    "    print(f\"Email drafts unsuccessfully generated. Error: {e}\")\n",
    "\n",
    "cols: list[str] = [\n",
    "    \"customer_id\", \n",
    "    \"email_draft\"\n",
    "]\n",
    "\n",
    "df_rfm.head(50)[cols].to_csv(\"../data/processed/marketing_campaign_drafts.csv\", index=False)\n",
    "del cols"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
