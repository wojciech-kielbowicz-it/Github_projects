{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91eaf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from huggingface_hub import InferenceClient\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types, text, Engine\n",
    "import time\n",
    "\n",
    "from src import database_methods as dbm\n",
    "from src import ai_agent_methods as aiam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af7e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "client: InferenceClient = InferenceClient(\n",
    "    api_key=os.environ[\"HF_TOKEN\"],\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"HuggingFaceH4/zephyr-7b-beta:featherless-ai\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the capital of France?\"\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    print(f\"Model answer (What is the capital of France?):\\n{completion.choices[0].message.content}\")\n",
    "except Exception as e:\n",
    "    print(\"Model unsuccessfully loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f652e6",
   "metadata": {},
   "source": [
    "## Due to the fact that the data did not contain customer e-mail data, e-mail addresses will be generated, especially for the project, from the prefix \"client_\", customer_id, and the suffix \"@mail.com\".\n",
    "\n",
    "## This data will be generated in an SQL query along with other parameters that will be useful for the AI ​​Agent to send emails to customers who have been inactive for some time to active customers for whom a discount in the store will be provided, encouraging them to make further purchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7b8ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    engine: Engine = dbm.get_db_engine()\n",
    "    print(\"DB Engine successfuly created\")\n",
    "except Exception as e:\n",
    "    print(f\"DB Engine creation error: {e}\")\n",
    "\n",
    "query: str = \"\"\"\n",
    "SELECT \n",
    "    customer_id, \n",
    "    SUM(quantity * price) AS monetary, \n",
    "    COUNT (DISTINCT order_id) AS frequency,\n",
    "    ((SELECT MAX(date) FROM e_commerce_order_details) - MAX(date)) AS recency, \n",
    "    ROUND((SUM(quantity * price) / (COUNT (DISTINCT order_id))), 2) AS average_order_value, \n",
    "\tCASE\n",
    "\t\tWHEN \n",
    "\t\t\t((SELECT MAX(date) FROM e_commerce_order_details) - MAX(date)) >= 90\n",
    "\t\tTHEN\n",
    "\t\t\t1\n",
    "\t\tELSE\n",
    "\t\t\t0\n",
    "\tEND AS churn, \n",
    "\tCONCAT('customer_', customer_id,'@mail.com') AS email\n",
    "FROM \n",
    "\te_commerce_order_details\n",
    "GROUP BY \n",
    "    customer_id;\n",
    "\"\"\"\n",
    "df_rfm: pd.DataFrame = pd.read_sql(\n",
    "    query, \n",
    "    engine\n",
    ")\n",
    "\n",
    "print(df_rfm.sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c354297",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_monetary = np.round(df_rfm[\"monetary\"].quantile(0.80), 2)\n",
    "print(type(threshold_monetary))\n",
    "print(f\"Monetary threshold:\\n{threshold_monetary}\", \"\\n\")\n",
    "threshold_frequency = np.round(df_rfm[\"frequency\"].quantile(0.80), 2)\n",
    "print(f\"Frequency threshold:\\n{threshold_frequency}\", \"\\n\")\n",
    "threshold_aov = np.round(df_rfm[\"average_order_value\"].quantile(0.80), 2)\n",
    "print(f\"Average order value threshold:\\n{threshold_aov}\", \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e57d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (df_rfm[\"churn\"] == 1),\n",
    "    (\n",
    "        (df_rfm[\"churn\"] == 0) & (\n",
    "            (df_rfm[\"monetary\"] >= threshold_monetary)\n",
    "            | \n",
    "            (df_rfm[\"frequency\"] >= threshold_frequency)\n",
    "            | \n",
    "            (df_rfm[\"average_order_value\"] >= threshold_aov)\n",
    "            )\n",
    "    )\n",
    "]\n",
    "print(type(conditions))\n",
    "choice: list[str, str] = [\n",
    "    \"churn_recovery\", \n",
    "    \"vip_loyalty\"\n",
    "]\n",
    "\n",
    "df_rfm[\"segmentation\"] = np.select(conditions, choice, default=\"standard_promo\")\n",
    "print(df_rfm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00324350",
   "metadata": {},
   "outputs": [],
   "source": [
    "vip_loyalty_prompt: str = r\"\"\"\n",
    "    You are a Customer Success Manager for a premium brand. \n",
    "    Write a short, exclusive appreciation email to our VIP customer. \n",
    "    Thank them for their loyalty. \n",
    "    Offer a special 20% discount on their next purchase with code: VIP20. \n",
    "    Tone: Professional, grateful, and exclusive. \n",
    "    Keep it under 100 words. Do not use hashtags.\n",
    "\"\"\"\n",
    "churn_recovery_prompt: str = r\"\"\"\n",
    "    You are a warm and friendly Customer Support Specialist. \n",
    "    Write a 'We Miss You' email to a customer who hasn't purchased in a while. \n",
    "    Convince them to come back. \n",
    "    Offer a 15% welcome back discount with code: MISSYOU15. \n",
    "    Tone: Empathetic, warm, casual. \n",
    "    Keep it under 80 words.\"\n",
    "\"\"\"\n",
    "\n",
    "standard_promo_prompt: str = r\"\"\"\n",
    "    You are an energetic Marketing Copywriter. \n",
    "    Write a catchy promotional email to an active customer. \n",
    "    Encourage them to check out our new arrivals. \n",
    "    Offer a 10% discount on the next order with code: HELLO10. \n",
    "    Tone: Exciting, direct, sales-oriented. \n",
    "    Keep it under 80 words.\n",
    "\"\"\"\n",
    "\n",
    "prompt: dict[str,str] = {\n",
    "    \"vip_loyalty\": vip_loyalty_prompt, \n",
    "    \"churn_recovery\": churn_recovery_prompt, \n",
    "    \"standard_promo\": standard_promo_prompt\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f36a507",
   "metadata": {},
   "source": [
    "# Methodology: AI Content Generation & API Integration\n",
    "This module implements an LLM-based (Large Language Model) agent to automate personalized marketing communication. Below are the key technical decisions and the rationale behind the chosen data flow architecture.\n",
    "\n",
    "1. Simulation Mode (\"Dry Run\") & Data Safety\n",
    "For safety reasons and development purposes, no actual emails are transmitted to customer addresses.\n",
    "\n",
    "Process: Generated content is stored directly within the pandas.DataFrame as a new feature (e.g., email_draft).\n",
    "\n",
    "Persistence: Upon completion, the enriched dataset is exported to a .csv / .parquet file. This allows for a Human-in-the-Loop (HITL) approach, where drafts undergo Quality Assurance (QA) before any potential production deployment.\n",
    "\n",
    "2. Sequential Execution Strategy (Single-Threaded)\n",
    "The system utilizes the pandas .apply() method for row-by-row processing. While vectorization is typically preferred in Data Science for performance, sequential processing is the optimal architectural choice in this specific context.\n",
    "\n",
    "We deliberately avoided Parallel Processing (e.g., joblib, multiprocessing) due to the constraints of the Hugging Face Serverless Inference API (Free Tier):\n",
    "\n",
    "API Rate Limiting: The free tier imposes strict limits on the number of requests per second (QPS). Parallel execution would trigger simultaneous requests, resulting in immediate HTTP 429 (Too Many Requests) errors and token suspension.\n",
    "\n",
    "I/O Bound Process: The bottleneck is not local CPU computation power, but Network Latency (waiting for the server to generate text).\n",
    "\n",
    "Traffic Control: Using a sequential loop within .apply() allows for precise pacing via time.sleep(). This ensures the script respects the API's concurrency limits and maintains stability throughout the ETL process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4a4df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_test: pd.DataFrame = df_rfm.sample(3)\n",
    "df_test[\"email_draft\"] = df_test.apply(aiam.generate_email, axis=1, args=(client, prompt))\n",
    "for i in range(3):\n",
    "    print(df_test[\"email_draft\"].iloc[i])\n",
    "    print(50 * \"-\")\n",
    "del df_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
